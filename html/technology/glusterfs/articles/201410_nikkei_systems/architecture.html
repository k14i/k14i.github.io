
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>GlusterFSのアーキテクチャ &#8212; k14i.github.io 1.0.0 documentation</title>
    <link rel="stylesheet" href="../../../../_static/pyramid.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Neuton&amp;subset=latin" type="text/css" media="screen" charset="utf-8" />
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Nobile:regular,italic,bold,bolditalic&amp;subset=latin" type="text/css" media="screen" charset="utf-8" />
<!--[if lte IE 6]>
<link rel="stylesheet" href="../../../../_static/ie6.css" type="text/css" media="screen" charset="utf-8" />
<![endif]-->

  </head><body>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="nav-item nav-item-0"><a href="../../../../index.html">k14i.github.io 1.0.0 documentation</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="glusterfs">
<h1>GlusterFSのアーキテクチャ<a class="headerlink" href="#glusterfs" title="Permalink to this headline">¶</a></h1>
<p>GlusterFSは、オープンソースの分散ファイルシステムである。一般的にストレージはブロックストレージ、ファイルストレージ、オブジェクトストレージに大別されるが、GlusterFSはファイルストレージに分類され、その中でもPOSIX準拠のインタフェースを持つ、ファイルシステムである。
なお、このような分散データストアは、グリッドコンピューティングにおけるストレージグリッドに由来するもので、複数のノードを接続することで、単一のボリュームを実現する。</p>
<img alt="technology/glusterfs/articles/201410_nikkei_systems/表1「ストレージアーキテクチャの典型的な分類」" src="technology/glusterfs/articles/201410_nikkei_systems/表1「ストレージアーキテクチャの典型的な分類」" />
<div class="section" id="id1">
<h2>システム・アーキテクチャ<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id2">
<h3>他の分散ファイルシステムと比較した特徴<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>GlusterFSが実現するシステムのアーキテクチャについて、他のプロダクトと比較した上での特徴は、3点挙げられる。</p>
<ul class="simple">
<li>シンプルなサーバとリッチなクライアント</li>
<li>中央サーバを持たない</li>
<li>多様なインタフェース</li>
</ul>
<div class="section" id="id3">
<h4>シンプルなサーバとリッチなクライアント<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h4>
<p>GlusterFSは、サーバ・クライアント型のアーキテクチャを取る。サーバは、ストレージ領域を提供することに徹し、そのストレージ領域を組み合わせてクラスタを構成する機能は、クライアント側で持っている。すなわち、実際にクライアントにてファイルの入出力が行われた場合に、それをどのノードに分散配置するかの決定、又はファイルのレプリケーション（複製）の処理などを、クライアントが行う。
また、クライアントは、NFSサーバ機能の提供も行う。この場合、NFSクライアントにはGlusterFSのインストールは不要である。</p>
</div>
<div class="section" id="id4">
<h4>中央サーバを持たない<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h4>
<p>メタデータサーバやネームノードのような、中央集権的にクラスタを管理するノードを、GlusterFSは持たない。メタデータを持ってはいるが、それらはファイルやディレクトリに対してExtended Attributeとして付与される。また、後述するが、データの配置はアルゴリズムにより決定される。
このアーキテクチャにより、ノードの追加によるスループットのリニアなスケールアウトが容易に実現可能となっている。また、SPOFとなり得るノードの冗長性及び堅牢性を高める等の工夫も不要となっている。
反面、基本的にデータの分散配置を最適化すること、言い換えればデータの偏りを是正するなど、きめ細かなデータの分散ができないアーキテクチャである。</p>
<img alt="technology/glusterfs/articles/201410_nikkei_systems/図1「プロセスから見るGlusterFS」" src="technology/glusterfs/articles/201410_nikkei_systems/図1「プロセスから見るGlusterFS」" />
</div>
<div class="section" id="id5">
<h4>多様なインタフェース<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h4>
<p>ユーザ空間実装のファイルシステムで多く使われるFUSEを利用した、GlusterネイティブプロトコルでのPOSIX準拠インタフェースに加え、NFS version 3、VFSプラグインとSambaを利用したCIFSプロトコル、Swiftのフロントエンドを組み込んだRESTfulなHTTPオブジェクトストレージ、libgfapiの提供によるC言語インタフェース、QEMUとのインテグレーションにより実現したqemu-kvmからのブロックストレージとしての利用、bd xlatorとLVMの組合せによるブロックストレージとしての利用が可能となっている。</p>
<img alt="technology/glusterfs/articles/201410_nikkei_systems/図2「OSから見るGlusterFS」" src="technology/glusterfs/articles/201410_nikkei_systems/図2「OSから見るGlusterFS」" />
</div>
</div>
<div class="section" id="id6">
<h3>分散ファイルシステムに共通する部分の特徴<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<p>ここからは、他のプロダクトと共通するアーキテクチャの解説を行う。</p>
<p>GlusterFSにおいて、クラスタのことをストレージプールと呼ぶ。1つのpeerは、複数のストレージプールに所属することができない。peerが1つも存在しない状況下で、あるノードから別のノードをコマンドでpeerとして指定した場合に、その2つのpeerによるストレージプールが生成される。
ストレージプールの中には、複数のvolumeを作成することができる。volumeは、brickと呼ばれるGlusterFSサーバのディレクトリパスを集約したものとなる。volumeの作成はglusterコマンドから実行する。これには通常、root権限が必要となっている。なお、brickの作成はvolumeの作成時に自動的に行われるため、特に意識する必要は無い。
ここまでの解説の範囲で、よく使用される構成でのコマンドを以下に示す。</p>
<ul class="simple">
<li>peerの指定</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># gluster peer probe &lt;ホスト名又はIPアドレス&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li>volumeの作成</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># gluster volume create &lt;volume名&gt; replica 2 &lt;peer1&gt;:/PATH/TO/BRICK &lt;peer2&gt;:/PATH/TO/BRICK ...</span>
</pre></div>
</div>
<ul class="simple">
<li>volumeの起動</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># gluster volume start &lt;volume名&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li>volumeのマウント</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># mount -t glusterfs localhost:&lt;volume名&gt; /PATH/TO/MOUNT</span>
</pre></div>
</div>
<p>この手順により、マウントポイント /PATH/TO/MOUNT にGlusterネイティブプロトコルでvolumeがマウントされる。先述の通り、GlusterFSクライアントがファイルの主要なハンドリングを行う。そのため、2レプリケーション構成である本構成においては、マウントポイントを持っている当該クライアントが、ファイルの分散配置先の決定やレプリケーションを行う。</p>
<p>以下、ファイルの分散配置及びレプリケーションに関連するアーキテクチャについて解説する。</p>
<div class="section" id="id7">
<h4>ファイルの分散配置<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h4>
<p>複数のノードに跨るファイルの分散配置は、分散データストアが共通して持つ基本的な機能である。分散配置が可能となることで、複数のノードが持つストレージ領域を、集約された単一のボリュームとして提供することができる。</p>
<img alt="technology/glusterfs/articles/201410_nikkei_systems/図3「分散」" src="technology/glusterfs/articles/201410_nikkei_systems/図3「分散」" />
<p>この分散配置をどのように実現するかが、各種分散データストアを特徴付ける共通要素であると言える。これについて大別すると、ストレージリソースの状況を把握している中央サーバがデータの配置先のノードをクライアントに指定することで、利用効率の最大化及びクライアントにかかる負荷の最小化を図るタイプと、中央サーバを持たずにアルゴリズムベースでデータを分散することで、オーバーヘッドの最小化、性能のリニアなスケールアウト及びSPOFの排除を図るタイプがある。GlusterFSは後者に分類される。</p>
<p>GlusterFSは、DHT(分散ハッシュテーブル)を利用して、ファイルを分散配置する。DHTのアルゴリズムは、コンシステントハッシュ法をベースにGlusterFSプロジェクトで独自に開発したElastic Hashing Algorithmである。詳細は後述する。</p>
</div>
<div class="section" id="id8">
<h4>データのレプリケーション<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h4>
<p>一方、データのレプリケーションは、分散データストアとしては必須ではないが、多くのそれらが共通して持つ機能である。レプリケーションのポイントは2点、データをどのように転送するかと、データをどのように保持するかにある。</p>
<div class="section" id="id9">
<h5>データをどのように転送するか<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h5>
<p>まず、データのレプリケーションにおいて、それらをどのように転送するかについて解説する。
GlusterFSにおいて、データの複製を行うのは、Glusterネイティブのクライアントである。これは、ユーザがNFSでGlusterFSをマウントする場合も同様である。<a class="footnote-reference" href="#id11" id="id10">[1]</a></p>
<table class="docutils footnote" frame="void" id="id11" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id10">[1]</a></td><td>この場合、GlusterネイティブのクライアントがNFSサーバ機能を提供する。そのため、NFSクライアントはレプリケーションを意識することは無い。</td></tr>
</tbody>
</table>
<p>Glusterネイティブクライアントは、入力されたデータ（ファイル）をコピーすることで、volumeに予め定義された数にまで複製を行い、それぞれ異なるbrickへと転送する。どのbrickに転送するかは、volumeの構成に従って静的に決定される。<a class="footnote-reference" href="#id13" id="id12">[2]</a></p>
<table class="docutils footnote" frame="void" id="id13" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id12">[2]</a></td><td>gluster volume create コマンドの引数に渡したbrickの順序と、replicaを指定した場合はその数値によって、データの複製が行われるbrickの組が決定される。ノードを追加する場合は、指定したreplicaの数に応じて、brickの組を指定する必要があり、そのbrick同士でデータの複製が行われることとなる。</td></tr>
</tbody>
</table>
<p>この転送処理は、データの複製を保持するbrickの組に対して、並行して行われる。後述するが、GlusterFSにおけるデータ保持の方式上、ファイルの書き込みにあたっては、レプリカの数に応じたトラフィックが発生することに留意する必要がある。すなわち、クライアント・サーバ間でのトラフィックはレプリカ数に比例、言い換えれば、各レプリカのスループットはレプリカ数に反比例することとなる。例えば、レプリカ数が2である場合、GlusterFSクライアントからは2つのbrickに対して同時に同じデータを2つ書き込むこととなる。この場合、スループットが1Gbpsのネットワークを使用していても、GlusterFSクライアントにとっては、実行スループットは512Mbps相当となる。この点、バックエンドでレプリケーションが行われる分散データストアと比較すると、短所になると言えるが、その反面、同期的な書き込みによるレプリケーションの確実性 <a class="footnote-reference" href="#id15" id="id14">[3]</a> が、エンタープライズ分野で選ばれる理由の一つとなっているのもまた事実である。</p>
<table class="docutils footnote" frame="void" id="id15" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id14">[3]</a></td><td>どのソフトウェアも確実性は設計上担保しているが、非同期処理の難しさに起因する実装ミスにより、レプリケーションが行われないケースは存在する。</td></tr>
</tbody>
</table>
<p>なお、転送中に書き込み先の一部のbrick上で障害が発生した場合、そのbrickは各クライアントから切断され、残りのbrickに対してデータの転送が継続されることとなる。GlusterFSのクラスタ内において、ノードは互いにヘルスチェックを行っており、プロセスダウン程度であれば即座に、ネットワーク障害であればタイムアウト（デフォルトで42秒）を待ってから、障害ノードの切り離しが行われる。なお、切り離されたノードの代替となるノードをクラスタ内から補填する機能は無く、残されたノードで機能提供を継続することとなる。</p>
</div>
<div class="section" id="id16">
<h5>データをどのように保持するか<a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h5>
<p>複製されるデータをどのように保持するかに関して、一般的な方式は2つに大別される。RAID 1のように同じブロック，ファイル，又はチャンクをミラーリングして保持する方式、そしてRAID 5やRAID 6のようにデータを加工し、パリティ等何らかのリカバリ手段を用意した上でデータを保持する方式である。なお、後者の方式の一つとしてErasure codingが最近注目を集めている。GlusterFSは、前者の方式のうち、複数のノードで同一のファイルをミラーリングする方式を採用している。</p>
<p>いずれの方式にも長所と短所があるが、GlusterFSが享受している長所としては、データの保全性であろう。GlusterFSのバックエンドにはKernel空間で実装された一般的なファイルシステム（Ext4やXFSなど）があり、データはファイル単位でそこに格納される。そのため、万が一GlusterFSが壊れて動作しなくなってしまった場合においても、各brick上からGlusterFSを介さずにデータへアクセスすることが可能である。<a class="footnote-reference" href="#id18" id="id17">[4]</a></p>
<table class="docutils footnote" frame="void" id="id18" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id17">[4]</a></td><td>GlusterFSとしては想定していない使い方であり、通常利用では推奨されない。</td></tr>
</tbody>
</table>
<p>この点、分散データストアがエンタープライズ分野において歴史が浅い中、GlusterFSが選ばれる大きな理由の一つである。実際、過去にGlusterFSクライアントが高負荷・無応答となった場合でも、データが消失していないことを、各brick上からローカルファイルシステムを参照する方法で確認した事例は複数存在する。このような運用が可能であるのも、GlusterFSがバックエンドにファイルシステムを利用し、データの保持をそこに一任しているためであると言える。</p>
<p>一方で、このレプリケーション方式の短所としては、レプリカ数に応じてデータ量が膨れ上がることにある。標準である2レプリケーション構成において、容量に対する効率は良くはなく、GlusterFS 3.6で機能追加されるdisperseトランスレータ（Erasure codeの実装）が期待される。</p>
</div>
<div class="section" id="self-heal">
<h5>self-heal<a class="headerlink" href="#self-heal" title="Permalink to this headline">¶</a></h5>
<p>また、GlusterFSはレプリケーション機能を利用してデータの修復機能である「self-heal」を実現している。これにより、一部ノードが障害から復旧した際に、データが自動的に正しい状態へと修復される。</p>
<img alt="technology/glusterfs/articles/201410_nikkei_systems/図4「レプリケーションとself-heal」" src="technology/glusterfs/articles/201410_nikkei_systems/図4「レプリケーションとself-heal」" />
<p>詳細は後述する。</p>
</div>
</div>
</div>
</div>
<div class="section" id="id19">
<h2>ソフトウェア・アーキテクチャ<a class="headerlink" href="#id19" title="Permalink to this headline">¶</a></h2>
<p>ここまでシステムとしてのアーキテクチャについて述べたが、一歩踏み込んで、ソフトウェア内部のアーキテクチャについても触れたい。</p>
<div class="section" id="id20">
<h3>拡張性の高さ<a class="headerlink" href="#id20" title="Permalink to this headline">¶</a></h3>
<p>GlusterFSは、C言語で記述されており、しかしながら、コードはオブジェクト指向で書かれている。GlusterFSの大きな特徴の一つは、クリーンで再利用が容易なコードがもたらす拡張性にあると言える。GlusterFSの機能は「トランスレータ」としてモジュール化されており、この組み合わせによって、まさに”Software Defined Storage”を実現するものである。モジュールの組み合わせはvolumeごとに定義でき、その定義をgraphという。GlusterFSは、バージョン3.0まではこのgraphを設定ファイルとして記述しなければならなかったが、それ以後のバージョンでは、管理者がgraphを意識する必要はなくなっている。</p>
<p>以下に、graphの一例を示す。なお、本稿で扱わないモジュールについては記載を省略した。</p>
<img alt="technology/glusterfs/articles/201410_nikkei_systems/図5「GlusterFSのgraph構造(概要)」" src="technology/glusterfs/articles/201410_nikkei_systems/図5「GlusterFSのgraph構造(概要)」" />
<p>入力されたデータや命令を、複数のトランスレータがそれぞれの処理を行うことで、GlusterFSはストレージとしての機能を提供する。このトランスレータを記述し、差し込んだり入れ替えたりすることで、GlusterFSはその機能を自在に変更できるアーキテクチャとなっている。
そのため、GlusterFSの機能追加スピードは、他の競合ソフトウェア等と比較しても非常に早く、機能の内容も自由度が高くなっている。</p>
<p>なお、GlusterFS 3.1以降では、ユーザ側でトランスレータを独自開発する際の敷居が上がってしまったが、GlusterFS 3.7以降で、そのような独自トランスレータを導入するための改善が予定されている。また、既存のGluPy（グルーピー）という仕組みを利用することで、Pythonで簡単に独自トランスレータを記述することもできる。このように、ソフトウェア・アーキテクチャが実現する高い柔軟性も、GlusterFSの魅力の一つである。</p>
</div>
<div class="section" id="id21">
<h3>ユーザランドでの実装<a class="headerlink" href="#id21" title="Permalink to this headline">¶</a></h3>
<p>ソフトウェア・アーキテクチャに関して、GlusterFSの開発の自由度やスピードを支える要因はもう一つある。それは、GlusterFSがユーザランドで実装されているということである。これにより、カーネルランドで実装するよりも遥かに手軽に実装することができる。他のツールとの連携もしやすい。
しかし、ユーザランドでの実装にはデメリットもある。カーネルランドで実装するよりも、性能面で不利であるということである。
GlusterFSで入出力されるデータは、TCP/IPネットワークを経由するだけでなく、クライアントとサーバの両方で、ユーザ空間とカーネル空間との間のメモリ内コピーが発生する。そもそも分散ファイルシステムとして大容量のデータの入出力が主たる用途となっているGlusterFSにおいて、このアーキテクチャは性能面でネガティブな影響を与える。
多くの導入ケースでGlusterFSの性能評価が行われており、意外と良いという評価も、意外と悪いという評価もある。これは性能要件やベンチマーク方法によって変わってくるものだが、思ったよりも性能が出ない場合には、このソフトウェア・アーキテクチャを加味して考察を行うと良いだろう。</p>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><div id="toc" class="sidebarRow">
  <h3><a href="https://github.com/k14i">My repository</a></h3>

  <h3><a href="../../../../index.html">Table Of Contents</a></h3>
  <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../computer_science/index.html">Computer Science</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../development/elixir/index.html">Elixir</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../development/c/index.html">C</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../development/programming_languages/index.html">Programming Languages</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../operation_and_monitoring/index.html">Operation and Monitoring</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../index.html">GlusterFS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docker/index.html">Docker</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../data_science/bayesian_statistics/bayes_theorem/index.html">Bayes’ theorem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../data_science/personal_data_protection/index.html">Personal Data Protection</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../others/sphinx/index.html">Sphinx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../others/presentation/index.html">Presentation</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../reports/2014/erlang_factory_sf_bay_area_2014/index.html">Erlang Factory SF Bay Area 2014</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../reports/2015/strata+hadoop_world_2015/index.html">Strata + Hadoop World 2015</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../media/twitter/timeline.html">Timeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../media/twitter/favorites.html">Favorite Tweets</a></li>
</ul>

  
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../../../_sources/technology/glusterfs/articles/201410_nikkei_systems/architecture.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="nav-item nav-item-0"><a href="../../../../index.html">k14i.github.io 1.0.0 documentation</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2015-2021, Keisuke Takahashi.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.7.9.
    </div>
  </body>
</html>