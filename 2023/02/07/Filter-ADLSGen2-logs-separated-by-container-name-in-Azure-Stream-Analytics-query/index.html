<!DOCTYPE html><html lang="ja"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="alternative" href="/atom.xml" title="kt.log" type="application/atom+xml"><link rel="icon" href="/favicon.png"><title>Filter ADLS Gen2 logs separated by container name in Azure Stream Analytics query - kt.log</title>
<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="/js/fancybox/jquery.fancybox.min.css">
<!--[if lt IE 9]><script>(function(a,b){a="abbr article aside audio bdi canvas data datalist details dialog figcaption figure footer header hgroup main mark meter nav output progress section summary template time video".split(" ");for(b=a.length-1;b>=0;b--)document.createElement(a[b])})()</script><![endif]-->
<script src="/js/jquery-3.1.1.min.js"></script>

<script src="/js/fancybox/jquery.fancybox.min.js"></script>
<meta name="generator" content="Hexo 6.2.0"></head><body style="opacity:0"><header class="head"><h1 class="head-title u-fl"><a href="/">kt.log</a></h1><nav class="head-nav u-fr"><ul class="head-nav__list"><li class="head-nav__item"><a class="head-nav__link" href="/archives">Articles</a></li><li class="head-nav__item"><a class="head-nav__link" href="/tags">Tags</a></li><li class="head-nav__item"><a class="head-nav__link" href="/links">Links</a></li></ul></nav></header><main class="main"><article class="post"><header class="post__head"><time class="post__time" datetime="2023-02-07T08:09:56.000Z">2023-02-07 17:09:56</time><h1 class="post__title"><a href="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/">Filter ADLS Gen2 logs separated by container name in Azure Stream Analytics query</a></h1><div class="post__main echo"><h1 id="Azure-Stream-Analytics-のクエリ内で-Azure-Data-Lake-Storage-Gen2-のログをコンテナー名ごとにフィルタリングする"><a href="#Azure-Stream-Analytics-のクエリ内で-Azure-Data-Lake-Storage-Gen2-のログをコンテナー名ごとにフィルタリングする" class="headerlink" title="Azure Stream Analytics のクエリ内で Azure Data Lake Storage Gen2 のログをコンテナー名ごとにフィルタリングする"></a>Azure Stream Analytics のクエリ内で Azure Data Lake Storage Gen2 のログをコンテナー名ごとにフィルタリングする</h1><h2 id="Azure-Data-Lake-Storage-Gen2-で取得可能なログ"><a href="#Azure-Data-Lake-Storage-Gen2-で取得可能なログ" class="headerlink" title="Azure Data Lake Storage Gen2 で取得可能なログ"></a>Azure Data Lake Storage Gen2 で取得可能なログ</h2><p><a target="_blank" rel="noopener" href="https://learn.microsoft.com/azure/storage/blobs/data-lake-storage-introduction">Azure Data Lake Storage Gen2</a> (以下 ADLS Gen2 という) を利用する中で、セキュリティ監査のために操作ログを収集・蓄積したいというニーズはあると思います。</p>
<p>ADLS Gen2 で取得可能なログは以下の通りです。</p>
<ol>
<li>プラットフォーム ログとメトリック</li>
<li><a target="_blank" rel="noopener" href="https://learn.microsoft.com/azure/storage/common/storage-analytics">Storage Analytics</a> ログ</li>
</ol>
<p>プラットフォーム ログとメトリックは、ストレージ アカウントの <code>[監視] &gt; [診断設定]</code> から設定できます。リソースの種類 (ストレージ アカウント, blob, queue, table, file) ごとに取得するログを指定することができ、ADLS Gen2 のログに関しては blob についての設定を行います。<br>blob のログは <code>StorageRead</code>, <code>StorageWrite</code>, <code>StorageDelete</code>, <code>Transaction</code> の 4種類を取得することができ、そのうち <code>Transaction</code> はメトリックに関するもの、それ以外の 3つは操作ログです。<br>これらのログおよびメトリックは、複数の宛先に送信または保存することができます。具体的には (1) Log Analytics ワークスペース (2) ストレージ アカウント (3) イベント ハブ (4) パートナー ソリューション です。これら外部のしくみを使って、ログを蓄積・活用することができます。</p>
<p>一方、Storage Analytics ログは、ストレージ アカウントの <code>[監視 (クラシック)] &gt; [診断設定 (クラシック)]</code> から設定できます。こちらもメトリック、および各種操作ログ (読み取り, 書き込み, 削除) を取得することができます。ログは時間単位または分単位で取得することができ、データの削除をするかどうか、何日後にデータを削除するか (最短1日、最長365日) を指定することができます。<br>Storage Analytics ログは、同ストレージ アカウントに最初から存在する特殊なコンテナー <code>$logs</code> に保存されます。<br>Storage Analytics ログを分析するためには、AzCopy 等を使用して <a target="_blank" rel="noopener" href="https://learn.microsoft.com/azure/storage/common/manage-storage-analytics-logs?tabs=azure-portal#view-log-data">ログをローカルマシンにダウンロードする必要があります</a>。</p>
<p>ここで頭の片隅に置いておきたいのは、 <code>$logs</code> コンテナーは、他の Azure サービスからは不可視であるという点です。<a target="_blank" rel="noopener" href="https://learn.microsoft.com/azure/event-hubs/">Azure Event Hubs</a>, <a target="_blank" rel="noopener" href="https://learn.microsoft.com/azure/stream-analytics/">Azure Stream Analytics</a>, <a target="_blank" rel="noopener" href="https://learn.microsoft.com/azure/data-factory/">Azure Data Factory</a>, <a target="_blank" rel="noopener" href="https://learn.microsoft.com/azure/logic-apps/">Azure Logic Apps</a>、こういった ADLS Gen2 と接続してデータを抽出してこれるようなサービスで、 <code>$logs</code> コンテナーを指定することができません。</p>
<p>したがって、ADLS Gen2 のログを活用したいのであれば、プラットフォーム ログとメトリック を利用するのがオススメです。</p>
<h2 id="ADLS-Gen2-のログ活用の課題"><a href="#ADLS-Gen2-のログ活用の課題" class="headerlink" title="ADLS Gen2 のログ活用の課題"></a>ADLS Gen2 のログ活用の課題</h2><p>ADLS Gen2 はエンタープライズ <a target="_blank" rel="noopener" href="https://learn.microsoft.com/azure/architecture/data-guide/scenarios/data-lake">データ レイク</a> です。企業内の様々な組織のユーザーが、様々な構造化データ・非構造化データを蓄積していきます。<br>ちなみに、<a target="_blank" rel="noopener" href="https://learn.microsoft.com/azure/azure-resource-manager/management/azure-subscription-service-limits#storage-limits">一つの ストレージ アカウント上に作成できるコンテナーの数は無制限</a>です。一つのコンテナーを企業全体でシェアするのか、組織等の単位でコンテナーを分けるのかは、企業のポリシー、カルチャー、プロジェクトの性質等によって様々です。<br>ただ、ログ活用の観点から留意したいこととしては、 <strong>ストレージ アカウントで出力できるログはすべてストレージ アカウント単位で出力される</strong> ということです。すなわち、 <strong>ログをコンテナー単位やディレクトリ単位で出力することはできません</strong> 。</p>
<p>例えば、企業IT部門がデータ レイクを管理していて、ユーザー部門に対してコンテナーを割り当てていると仮定します。そして <a target="_blank" rel="noopener" href="https://learn.microsoft.com/azure/role-based-access-control/overview">Azure RBAC</a> と <a target="_blank" rel="noopener" href="https://learn.microsoft.com/azure/storage/blobs/data-lake-storage-access-control-model#access-control-lists-acls">ACL</a> を使用して、コンテナーごとにアクセス制御を行っているとします。<br>各組織のコンテナー利用についてはこれで問題ありませんが、セキュリティ監査の一環として、コンテナーの操作ログを各組織が活用したいという場合に問題が発生します。<br>ログはストレージ アカウント単位でしか出力されないですし、その設定もストレージ アカウントのスコープで行うため、組織が自身のためにログ設定を行うと他の組織による設定と排他になりますし、ログを取得するにしても、他の組織のログもすべて取得できてしまいます。これはセキュリティ監査の観点からもよろしいことではありません。</p>
<p>もちろん、組織ごとにストレージ アカウントを分けるという手もありますが、企業のデータ利活用という観点では、制約となり得ます。すなわち、操作ログの活用のためだけに、データ レイクの利便性や可能性を制限するようなことは、本来したくないはずです。</p>
<p>したがって、ログの設定はデータ レイクの管理者である企業IT部門が行うとして、そのログを組織ごとに割り振る方法を考えます。なお、各組織はコンテナーを割り当てられていて、その単位で操作ログの監査を行うユースケースを想定します。</p>
<h2 id="プラットフォーム-ログのスキーマ"><a href="#プラットフォーム-ログのスキーマ" class="headerlink" title="プラットフォーム ログのスキーマ"></a>プラットフォーム ログのスキーマ</h2><p>プラットフォーム ログとメトリック のファイル形式は JSON です。 (ちなみに、Storage Analytics ログはセミコロン <code>;</code> 区切りの Delimited Text です。)<br><code>StorageRead</code> のログのうち、ADLS Gen2 上の blob を一覧表示した際に出力されるものを一例として示します。 (実際のログをもとにしていますが、一部の文字列はダミーで置き換えるか、伏せるか、変数ライクに加工する等しています。)</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;time&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1970-01-01T00:00:00.0000000Z&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;resourceId&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/subscriptions/&#123;SUBSCRIPTION_ID&#125;/resourceGroups/&#123;RESOURCE_GROUP_NAME&#125;/providers/Microsoft.Storage/storageAccounts/&#123;STORAGE_ACCOUNT_NAME&#125;/blobServices/default&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;category&quot;</span><span class="punctuation">:</span> <span class="string">&quot;StorageRead&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;operationName&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ListBlobs&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;operationVersion&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2018-03-28&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;schemaVersion&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;statusCode&quot;</span><span class="punctuation">:</span> <span class="number">200</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;statusText&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Success&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;durationMs&quot;</span><span class="punctuation">:</span> <span class="number">14</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;callerIpAddress&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&#123;IPv4_ADDRESS&#125;:&#123;PORT_NUMBER&#125;&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;correlationId&quot;</span><span class="punctuation">:</span> <span class="string">&quot;********-****-****-****-************&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;identity&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;AccountKey&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;tokenHash&quot;</span><span class="punctuation">:</span> <span class="string">&quot;key1(****************************************************************)&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;location&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&#123;REGION_NAME&#125;&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;properties&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;accountName&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&#123;STORAGE_ACCOUNT_NAME&#125;&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;userAgentHeader&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Azure-Storage/9.3.2 (.NET CLR 4.0.30319.42000; Win32NT 10.0.14393.0)&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;clientRequestId&quot;</span><span class="punctuation">:</span> <span class="string">&quot;********-****-****-****-************&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;serviceType&quot;</span><span class="punctuation">:</span> <span class="string">&quot;blob&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;objectKey&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/&#123;STORAGE_ACCOUNT_NAME&#125;/&#123;CONTAINER_NAME&#125;&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;metricResponseType&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Success&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;serverLatencyMs&quot;</span><span class="punctuation">:</span> <span class="number">13</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;requestHeaderSize&quot;</span><span class="punctuation">:</span> <span class="number">503</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;responseHeaderSize&quot;</span><span class="punctuation">:</span> <span class="number">152</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;responseBodySize&quot;</span><span class="punctuation">:</span> <span class="number">4652</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;tlsVersion&quot;</span><span class="punctuation">:</span> <span class="string">&quot;TLS 1.2&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;accessTier&quot;</span><span class="punctuation">:</span> <span class="string">&quot;None&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;uri&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://&#123;STORAGE_ACCOUNT_NAME&#125;.blob.core.windows.net:443/&#123;CONTAINER_NAME&#125;?restype=container&amp;comp=list&amp;prefix=&amp;delimiter=%2F&amp;maxresults=5000&amp;include=metadata&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;protocol&quot;</span><span class="punctuation">:</span> <span class="string">&quot;HTTPS&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;resourceType&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Microsoft.Storage/storageAccounts/blobServices&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    ...</span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>

<p>ログをコンテナーごとに振り分けるとして、利用価値があるであろうフィールドは以下の通りです。</p>
<ul>
<li>ストレージアカウント名 (STORAGE_ACCOUNT_NAME) が含まれるフィールド<ul>
<li><code>resourceId</code></li>
<li><code>properties.accountName</code></li>
<li><code>properties.objectKey</code></li>
<li><code>url</code></li>
</ul>
</li>
<li>コンテナー名 (CONTAINER_NAME) が含まれるフィールド<ul>
<li><code>properties.objectKey</code></li>
<li><code>url</code></li>
</ul>
</li>
</ul>
<p>課題へのアプローチとしては、コンテナー名が含まれるフィールドから少なくとも 1つ、可能であればストレージアカウント名が含まれるフィールドも組み合わせて、ログの各行がどのコンテナーのものであるかを判定し、その結果から異なる宛先に転送することとします。</p>
<h2 id="割り振りを行うサービスの選定"><a href="#割り振りを行うサービスの選定" class="headerlink" title="割り振りを行うサービスの選定"></a>割り振りを行うサービスの選定</h2><p>再掲となりますが、プラットフォーム ログとメトリックの宛先として利用できるサービスは以下の 4つです。</p>
<ol>
<li>Log Analytics ワークスペース</li>
<li>ストレージ アカウント</li>
<li>イベント ハブ</li>
<li>パートナー ソリューション</li>
</ol>
<p>本記事では、 Azure のサービスを利用することを想定します。<br>この中で上記の割り振りを実現するための最もシンプルな選択肢は、イベント ハブ (Azure Event Hubs) です。<br><a target="_blank" rel="noopener" href="https://learn.microsoft.com/azure/event-hubs/event-hubs-about">Azure Event Hubs</a> でログをキューイングし、 <a target="_blank" rel="noopener" href="https://learn.microsoft.com/azure/stream-analytics/stream-analytics-introduction">Azure Stream Analytics</a> でそれを取得、クエリを実行して割り振りを行い、異なる出力先に送る方式を考えます。</p>
<h2 id="Azure-Event-Hubs-の構成"><a href="#Azure-Event-Hubs-の構成" class="headerlink" title="Azure Event Hubs の構成"></a>Azure Event Hubs の構成</h2><p>Azure Event Hubs のリソースを 1つ、その中で名前空間を 1つ、それぞれ作成します。コンシューマー グループ はデフォルトで <code>$Default</code> が存在しますが、今は何もしなくて構いません。<br>もし ADLS Gen2 が複数ある場合は、それに合わせて Azure Event Hubs を複数作るか、1つの Azure Event Hubs リソースの中に名前空間を複数作ります。</p>
<p>また、今回 ADLS Gen2 の <code>StorageRead</code> を組織ごとに割り振ることを考えますが、他の <code>StorageWrite</code> や <code>StorageDelete</code> 、そしてメトリックである <code>Transaction</code> 、あるいは (ADLS Gen2 ではなく) ストレージ アカウントのメトリック <code>Transaction</code> も出力したい場合は、それぞれに対して名前空間を作るとよいでしょう。<br>理由は、それぞれログのスキーマが異なりますが、 Azure Stream Analytics ジョブ 1つあたりで実行できるクエリは 1つであるため、上記のように名前空間を分けて Azure Stream Analytics ジョブも分けることで、クエリの複雑化を防ぐことができるためです。</p>
<p>また、もし後続の Azure Stream Analytics ジョブを複数作って同じログを複数の宛先に送りたい場合は、コンシューマー グループを複数作ります。</p>
<p>以下に、Azure Event Hubs のデプロイ手順を示します。</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00001.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00002.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00003.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00004.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00005.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00006.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00007.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00008.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00009.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00010.png" class="slug">

<h2 id="ADLS-Gen2-のプラットフォーム-ログ設定"><a href="#ADLS-Gen2-のプラットフォーム-ログ設定" class="headerlink" title="ADLS Gen2 のプラットフォーム ログ設定"></a>ADLS Gen2 のプラットフォーム ログ設定</h2><p>Azure Event Hubs のリソースをデプロイして構成が完了したら、Azure Stream Analytics の構成を行う前に ADLS Gen2 のストレージ アカウントの <code>[監視] &gt; [診断設定]</code> からプラットフォーム ログの設定を行い、Azure Event Hubs にログを出力しておくことをオススメします。</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00011.png" class="slug">

<p>理由は、Azure Stream Analytics ではクエリの編集中に、実際のデータを使ってクエリの実行結果を確認しながら作業を進められるためです。そのためのログデータを Azure Event Hubs に流しておきます。</p>
<p>今回、プラットフォーム ログは blob について設定します。初期状態では診断の状態が　<code>無効</code> となっています。</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00012.png" class="slug">

<p>blob をクリック</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00013.png" class="slug">

<p><code>＋ 診断設定を追加する</code> をクリック</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00014.png" class="slug">

<p>今回は <code>StorageRead</code> を組織ごとに割り振るということで、 <code>[ログ] &gt; [カテゴリ] &gt; [StreageRead]</code> のチェックボックスをクリックしてチェックを入れます。</p>
<p>次に <code>[宛先の詳細] &gt; [イベント ハブへのストリーム]</code> のチェックボックスにチェックを入れます。<br>そして、サブスクリプション、イベント ハブの名前空間をそれぞれ選択します。他はデフォルト状態のままで構いません。</p>
<p><code>診断設定の名前</code> を付けておくことを忘れずに。</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00015.png" class="slug">

<p>最後に <code>[保存]</code> をクリックします。</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00016.png" class="slug">

<p>また、加えて、後で使用するログを生成するために、Azure Portal のストレージアカウント等からコンテナーにアクセスしておきましょう。</p>
<h2 id="Azure-Stream-Analytics-の構成"><a href="#Azure-Stream-Analytics-の構成" class="headerlink" title="Azure Stream Analytics の構成"></a>Azure Stream Analytics の構成</h2><p>Azure Stream Analytics ジョブのリソースを 1つ作成します。<br>作成手順を以下に示します。</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00017.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00018.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00019.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00020.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00021.png" class="slug">

<p>まずは入力と出力を定義します。<br>入力は先に作成してある Azure Event Hubs です。<br>出力については今ここで決めなくてもよいと思います。<br>各組織のリソースに直接出力する方式も考えられますし、振り分けたログをそれぞれいったん別の Azure Event Hubs にキューイングし、各組織は Azure Stream Analytics 等でそこからデータを取り出して任意の方法で蓄積・加工・分析を行う形も考えられます。</p>
<p>現時点では、出力先を定義せず、ログの振り分けにフォーカスしたいと思います。</p>
<h3 id="入力の追加"><a href="#入力の追加" class="headerlink" title="入力の追加"></a>入力の追加</h3><p><code>[ジョブ トポロジ] &gt; [入力]</code> をクリックし、入力に関する画面を開きます。</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00022.png" class="slug">

<p><code>[＋ ストリーム入力の追加]</code> をクリックし、 <code>イベント ハブ</code> をクリックします。</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00023.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00024.png" class="slug">

<p><code>*</code> の付いている必須項目の入力を行います。</p>
<table>
<thead>
<tr>
<th>必須項目</th>
<th>解説</th>
</tr>
</thead>
<tbody><tr>
<td>入力のエイリアス</td>
<td>名前です。後でクエリ内でこの名前を使いますので、入力が単一の場合はシンプルに <code>input</code> 等でもよいでしょうし、入力を複数定義する場合は識別可能なエイリアス名を付けます。エイリアス名は当該 Azure Stream Analytics ジョブ内でユニークである必要があります。</td>
</tr>
<tr>
<td>イベント ハブ設定を手動で行う &#x2F; サブスクリプションからイベント ハブを選択する</td>
<td>通常は後者 (デフォルト) で良いです。</td>
</tr>
<tr>
<td>イベント ハブの名前空間</td>
<td>先に作成してある Azure Event Hubs 名前空間を選択します。</td>
</tr>
<tr>
<td>イベント ハブ名</td>
<td>本記事においては既存のものを使用。当該 Azure Event Hubs 名前空間に作成した Event Hub (のインスタンス) を選択します。</td>
</tr>
<tr>
<td>イベント ハブ コンシューマー グループ</td>
<td>本記事においては新規作成 (デフォルト) を採用。コンシューマー グループ名にはデフォルトで <code>&#123;当該 Azure Stream Analytics のリソース名&#125;_&#123;イベント ハブ名&#125;_consumer_group</code>という文字列が入力されています。(入力のエイリアスを先に入力した場合。) コンシューマー グループ名は最大50文字であり、入力フォームでのバリデーションはしてくれないため、<code>保存</code> 後にバリデーション エラーとなる場合があります。この場合は、適宜修正して対応してください。ちなみに、新規作成ではなく既存のものを使用する場合、デフォルトで存在する <code>$Default</code> も選択可能です。</td>
</tr>
<tr>
<td>イベントシリアル化形式</td>
<td>プラットフォーム ログ は JSON 形式ですので、 <code>JSON</code> のままにしておいてください。</td>
</tr>
</tbody></table>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00025.png" class="slug">

<p>最後に　<code>保存</code> をクリックします。</p>
<h4 id="エラーとなった場合"><a href="#エラーとなった場合" class="headerlink" title="エラーとなった場合"></a>エラーとなった場合</h4><p>ここで <code>ジョブへの ID の追加に失敗しました</code> というエラーが発生する場合があります。</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00027.png" class="slug">

<p>この場合、あと少し時間が経てば自動的に解決することが多いですが、手動で解決する場合は、<a target="_blank" rel="noopener" href="https://learn.microsoft.com/azure/stream-analytics/event-hubs-managed-identity">リンク先にあるドキュメント</a>を参照しながら、当該 Azure Stream Analytics のマネージド ID を作成し、当該 Azure Event Hubs 名前空間における <code>Azure Event Hubs データ所有者</code> ロールを、そのマネージド ID に割り当ててください。</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00028.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00029.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00030.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00031.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00032.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00033.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00034.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00035.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00036.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00037.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00038.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00039.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00040.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00041.png" class="slug">

<p>繰り返しになりますが、時間が経てば解決することが多いです。手動で設定中に解決されている場合もエラーとなります。</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00042.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00043.png" class="slug">

<p>そのあと、Azure Stream Analytics に戻り、当該 Azure Event Hubs への接続をテストしてください。</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00044.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00045.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00046.png" class="slug">


<h3 id="クエリの作成"><a href="#クエリの作成" class="headerlink" title="クエリの作成"></a>クエリの作成</h3><p><code>[ジョブ トポロジ] &gt; [クエリ]</code> をクリックし、クエリに関する画面を開きます。</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00047.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00048.png" class="slug">

<p>一番右のペインの中断、行番号が振ってあるエリアがクエリを記述するエリアです。<br>初期状態で記述されているクエリは使用しません。使用するクエリで上書きします。</p>
<p>使用するクエリの例を示します。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">WITH</span> ReaderQuery <span class="keyword">AS</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> record <span class="keyword">FROM</span> [evh<span class="operator">-</span>diagnostics<span class="operator">-</span>stdatalake20230122aje<span class="operator">-</span><span class="type">blob</span><span class="operator">-</span>storageread]</span><br><span class="line">    <span class="keyword">CROSS</span> APPLY GetArrayElements(records) <span class="keyword">AS</span> record</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    record.arrayvalue.<span class="operator">*</span></span><br><span class="line"><span class="keyword">INTO</span></span><br><span class="line">    [cosmos<span class="operator">-</span>diag<span class="operator">-</span>stdatalake20230122aje<span class="operator">-</span><span class="type">blob</span><span class="operator">-</span>storageread]</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">    ReaderQuery</span><br><span class="line"><span class="keyword">WHERE</span></span><br><span class="line">    record.arrayvalue.resourceId <span class="keyword">LIKE</span> (<span class="string">&#x27;%/providers/Microsoft.Storage/storageAccounts/stdatalake20230122aje/blobServices/default&#x27;</span>)</span><br><span class="line">    <span class="keyword">AND</span> record.arrayvalue.properties.accountName <span class="operator">=</span> <span class="string">&#x27;stdatalake20230122aje&#x27;</span></span><br><span class="line">    <span class="keyword">AND</span> record.arrayvalue.properties.objectKey <span class="operator">=</span> <span class="string">&#x27;/stdatalake20230122aje/datalake1&#x27;</span></span><br><span class="line">    <span class="keyword">AND</span> record.arrayvalue.uri <span class="keyword">LIKE</span> (<span class="string">&#x27;https://stdatalake20230122aje.blob.core.windows.net:443/datalake1?%&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>以下、解説を行います。</p>
<hr>
<h4 id="WITH-句"><a href="#WITH-句" class="headerlink" title="WITH 句"></a>WITH 句</h4><p>クエリエンジンに入力されるデータは、プラットフォーム ログ そのままではなく、それを含む Azure Event Hubs のキューです。<br>具体的には以下のようなフォーマットになっています。</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;records&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="comment">// Azure Event Hubs が受信したプラットフォーム ログ</span></span><br><span class="line">  <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;EventProcessedUtcTime&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&#123;datetime型の日付&#125;&quot;</span><span class="punctuation">,</span> <span class="comment">// イベントが処理された日時</span></span><br><span class="line">  <span class="attr">&quot;PartitionId&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span> <span class="comment">// パーティションID</span></span><br><span class="line">  <span class="attr">&quot;EventEnqueuedUtcTime&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&#123;datetime型の日付&#125;&quot;</span> <span class="comment">// イベントがキューイングされた日時</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>Azure Stream Analytics で処理をして出力先に送信したいのは <code>records</code> 内のデータであるはずなので、この <code>WITH</code> 句では <code>records</code> からレコードを取り出して、後続の <code>SELECT ... FROM ...</code> の <code>FROM</code> に与えられるようにしています。</p>
<h4 id="SELECT-文"><a href="#SELECT-文" class="headerlink" title="SELECT 文"></a>SELECT 文</h4><p><code>record.arrayvalue.*</code> としています。これは、プラットフォーム ログのすべてのフィールドを指定しています。<br>フィールドを限定したい場合は、</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    record.arrayvalue.operationName <span class="keyword">AS</span> operationName,</span><br><span class="line">    record.arrayvalue.properties.metricResponseType <span class="keyword">AS</span> metricResponseType,</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>

<p>といった要領で個別に指定し、必要に応じて任意のフィールド名を付けたりします。</p>
<h4 id="INTO"><a href="#INTO" class="headerlink" title="INTO"></a>INTO</h4><p>ここではデフォルトのままで結構です。<br>後でクエリ結果の出力先のエイリアス名を指定します。</p>
<h4 id="FROM"><a href="#FROM" class="headerlink" title="FROM"></a>FROM</h4><p>クエリの実行対象を指定します。ここでは <code>WITH</code> 句を使って <code>ReaderQuery</code> からプラットフォーム ログを取り出せるようにしていますので、 <code>ReaderQuery</code> を指定します。<br>これにより、プラットフォーム ログの各行に対して <code>record</code> を用いることでアクセスできるようになります。</p>
<h4 id="WHERE-句"><a href="#WHERE-句" class="headerlink" title="WHERE 句"></a>WHERE 句</h4><p>プラットフォーム ログをコンテナー別で振り分けるのが、今回の課題でした。そのための条件を記述します。<br>ここでは、ストレージアカウント名とコンテナー名で細かく絞り込みを行っています。</p>
<hr>
<p>クエリ画面を開いたら、画面右下のペイン <code>入力のプレビュー</code> 配下に、入力データのプレビューが表示されます。これは、ここでは実際に Azure Event Hubs から取得したキューが使われています。</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00050.png" class="slug">

<p>作成したクエリをテストするには、 <code>クエリのテスト</code> をクリックします。これにより、入力のプレビューに対してクエリを実行し、 <code>テスト結果</code> から (出力先に出力される) 結果を確認することができます。</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00051.png" class="slug">

<p><code>テスト結果</code> には <code>結果をダウンロード</code> のリンクがあります。こちらから結果のデータをダウンロードし、 Visual Studio Code 等で JSON のフォーマットを行うと見やすくなります。コンテナー名で検索を行い、クエリによって正しくコンテナーの振り分けができているかどうか確認しましょう。</p>
<p>適宜クエリの修正とテスト結果の確認を行い、クエリが完成したら、 <code>クエリの保存</code> をクリックしてクエリを保存します。</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00052.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00053.png" class="slug">

<p>今回は ADLS Gen2 のコンテナーごとに <code>StorageRead</code> ログを振り分けたいので、各コンテナーに読み取りアクセスがあった際のデータをプレビュー入力として使います。<br>実際に各コンテナーに読み取りアクセスをしてログを生成することもできますが、繰り返し行うテストのデータの作成方法としては安定性・網羅性の観点からスマートではありません。<br><code>入力のプレビュー</code> 内 <code>サンプル データをダウンロードする</code> から実際のログを取得し、コンテナー名について網羅性のあるテストデータとなるような編集を行い、その JSON ファイルを <code>入力のプレビュー</code> 内 <code>サンプル入力のアップロード</code> からアップロードするのがオススメです。</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00049.png" class="slug">

<h3 id="出力の追加"><a href="#出力の追加" class="headerlink" title="出力の追加"></a>出力の追加</h3><p>入力の追加と同じ要領で、出力を追加します。(あるいは、クエリ画面から出力を追加することもできます。)</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00054.png" class="slug">

<p>今回は (Azure Stream Analytics ジョブへの入力に用いるものとは異なる) Azure Event Hubs を出力として指定します。</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00055.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00056.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00057.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00058.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00059.png" class="slug">


<h4 id="エラーとなった場合-1"><a href="#エラーとなった場合-1" class="headerlink" title="エラーとなった場合"></a>エラーとなった場合</h4><p>入力の追加と同様、ここで <code>ジョブへの ID の追加に失敗しました</code> というエラーが発生する場合があります。<br>また、出力テストの結果、接続テストが失敗することもあります。</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00060.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00061.png" class="slug">

<p>対処方法も基本的に同様です。手動で解決する場合、当該 Azure Stream Analytics のマネージド ID はすでに存在するため、当該 Azure Event Hubs 名前空間においてロールの追加を行ってください。</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00062.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00063.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00064.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00065.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00066.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00067.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00068.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00069.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00070.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00071.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00072.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00073.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00074.png" class="slug">


<h3 id="クエリの修正"><a href="#クエリの修正" class="headerlink" title="クエリの修正"></a>クエリの修正</h3><p><code>INTO</code> に与えるパラメータを、出力のエイリアスに書き換えます。</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00075.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00076.png" class="slug">

<p><del>画面中央のペインに、入力と出力のエイリアス名が表示されています。これは、既存のエイリアスと、クエリ内で指定されているエイリアス名です。<br>既に出力は追加されていますので、出力以下にそれらのエイリアス名以外が残らないように、気をつけてクエリを編集してください。</del></p>
<p>この時点で、元々 <code>YourOutputAlias</code> とされていた箇所が、出力エイリアス名で置き換えられています。<br>最終的なクエリは以下の通りです。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">WITH</span> ReaderQuery <span class="keyword">AS</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> record <span class="keyword">FROM</span> [evh<span class="operator">-</span>stloganalytics20230208a0<span class="operator">-</span><span class="type">blob</span><span class="operator">-</span>storageread]</span><br><span class="line">    <span class="keyword">CROSS</span> APPLY GetArrayElements(records) <span class="keyword">AS</span> record</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    record.arrayvalue.<span class="operator">*</span></span><br><span class="line"><span class="keyword">INTO</span></span><br><span class="line">    [evhns<span class="operator">-</span>LogAnalytics<span class="number">-20230208</span>a<span class="operator">-</span>JapanEast<span class="operator">-</span>container0]</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">    ReaderQuery</span><br><span class="line"><span class="keyword">WHERE</span></span><br><span class="line">    record.arrayvalue.resourceId <span class="keyword">LIKE</span> (<span class="string">&#x27;%/providers/Microsoft.Storage/storageAccounts/stloganalytics20230208a0/blobServices/default&#x27;</span>)</span><br><span class="line">    <span class="keyword">AND</span> record.arrayvalue.properties.accountName <span class="operator">=</span> <span class="string">&#x27;stloganalytics20230208a0&#x27;</span></span><br><span class="line">    <span class="keyword">AND</span> record.arrayvalue.properties.objectKey <span class="operator">=</span> <span class="string">&#x27;/stloganalytics20230208a0/container0&#x27;</span></span><br><span class="line">    <span class="keyword">AND</span> record.arrayvalue.uri <span class="keyword">LIKE</span> (<span class="string">&#x27;https://stloganalytics20230208a0.blob.core.windows.net:443/container0?%&#x27;</span>)</span><br></pre></td></tr></table></figure>


<h2 id="Azure-Stream-Analytics-の開始"><a href="#Azure-Stream-Analytics-の開始" class="headerlink" title="Azure Stream Analytics の開始"></a>Azure Stream Analytics の開始</h2><p><code>[概要]</code> 内、 <code>開始</code> をクリックして、ジョブを開始します。<br>順次ログが処理されて、出力先に出力されます。</p>
<h2 id="Appendix-参考用の構成"><a href="#Appendix-参考用の構成" class="headerlink" title="Appendix: 参考用の構成"></a>Appendix: 参考用の構成</h2><p>ここまでの解説では、振り分け処理にフォーカスしていたため、ADLS Gen2 のコンテナー 1つで解説をしてきました。<br>ここでは、コンテナーを 3つに増やし、 <code>StorageRead</code> のログについて、振り分け後に各組織のリソースに格納されるところまでを紹介します。</p>
<p>まず、リソース グループからみる最終的な構成は以下の通りです。</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00077.png" class="slug">

<p>そして、振り分け処理を行う Azure Stream Analytics ジョブのクエリは以下の通りです。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">WITH</span> ReaderQuery <span class="keyword">AS</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> record <span class="keyword">FROM</span> [evh<span class="operator">-</span>stloganalytics20230208a0<span class="operator">-</span><span class="type">blob</span><span class="operator">-</span>storageread]</span><br><span class="line">    <span class="keyword">CROSS</span> APPLY GetArrayElements(records) <span class="keyword">AS</span> record</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    <span class="keyword">LEFT</span>(record.arrayvalue.time, <span class="number">10</span>) <span class="keyword">AS</span> <span class="type">date</span>,</span><br><span class="line">    record.arrayvalue.<span class="operator">*</span></span><br><span class="line"><span class="keyword">INTO</span></span><br><span class="line">    [evh<span class="operator">-</span>stloganalytics20230208a0<span class="operator">-</span>container0<span class="operator">-</span><span class="type">blob</span><span class="operator">-</span>storageread]</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">    ReaderQuery</span><br><span class="line"><span class="keyword">WHERE</span></span><br><span class="line">    record.arrayvalue.resourceId <span class="keyword">LIKE</span> (<span class="string">&#x27;%/providers/Microsoft.Storage/storageAccounts/stloganalytics20230208a0/blobServices/default&#x27;</span>)</span><br><span class="line">    <span class="keyword">AND</span> record.arrayvalue.properties.accountName <span class="operator">=</span> <span class="string">&#x27;stloganalytics20230208a0&#x27;</span></span><br><span class="line">    <span class="keyword">AND</span> record.arrayvalue.properties.objectKey <span class="operator">=</span> <span class="string">&#x27;/stloganalytics20230208a0/container0&#x27;</span></span><br><span class="line">    <span class="keyword">AND</span> record.arrayvalue.uri <span class="keyword">LIKE</span> (<span class="string">&#x27;https://stloganalytics20230208a0.blob.core.windows.net:443/container0?%&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    <span class="keyword">LEFT</span>(record.arrayvalue.time, <span class="number">10</span>) <span class="keyword">AS</span> <span class="type">date</span>,</span><br><span class="line">    record.arrayvalue.<span class="operator">*</span></span><br><span class="line"><span class="keyword">INTO</span></span><br><span class="line">    [evh<span class="operator">-</span>stloganalytics20230208a0<span class="operator">-</span>container1<span class="operator">-</span><span class="type">blob</span><span class="operator">-</span>storageread]</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">    ReaderQuery</span><br><span class="line"><span class="keyword">WHERE</span></span><br><span class="line">    record.arrayvalue.resourceId <span class="keyword">LIKE</span> (<span class="string">&#x27;%/providers/Microsoft.Storage/storageAccounts/stloganalytics20230208a0/blobServices/default&#x27;</span>)</span><br><span class="line">    <span class="keyword">AND</span> record.arrayvalue.properties.accountName <span class="operator">=</span> <span class="string">&#x27;stloganalytics20230208a0&#x27;</span></span><br><span class="line">    <span class="keyword">AND</span> record.arrayvalue.properties.objectKey <span class="operator">=</span> <span class="string">&#x27;/stloganalytics20230208a0/container1&#x27;</span></span><br><span class="line">    <span class="keyword">AND</span> record.arrayvalue.uri <span class="keyword">LIKE</span> (<span class="string">&#x27;https://stloganalytics20230208a0.blob.core.windows.net:443/container1?%&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    <span class="keyword">LEFT</span>(record.arrayvalue.time, <span class="number">10</span>) <span class="keyword">AS</span> <span class="type">date</span>,</span><br><span class="line">    record.arrayvalue.<span class="operator">*</span></span><br><span class="line"><span class="keyword">INTO</span></span><br><span class="line">    [evh<span class="operator">-</span>stloganalytics20230208a0<span class="operator">-</span>container2<span class="operator">-</span><span class="type">blob</span><span class="operator">-</span>storageread]</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">    ReaderQuery</span><br><span class="line"><span class="keyword">WHERE</span></span><br><span class="line">    record.arrayvalue.resourceId <span class="keyword">LIKE</span> (<span class="string">&#x27;%/providers/Microsoft.Storage/storageAccounts/stloganalytics20230208a0/blobServices/default&#x27;</span>)</span><br><span class="line">    <span class="keyword">AND</span> record.arrayvalue.properties.accountName <span class="operator">=</span> <span class="string">&#x27;stloganalytics20230208a0&#x27;</span></span><br><span class="line">    <span class="keyword">AND</span> record.arrayvalue.properties.objectKey <span class="operator">=</span> <span class="string">&#x27;/stloganalytics20230208a0/container2&#x27;</span></span><br><span class="line">    <span class="keyword">AND</span> record.arrayvalue.uri <span class="keyword">LIKE</span> (<span class="string">&#x27;https://stloganalytics20230208a0.blob.core.windows.net:443/container2?%&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>これまでの説明では振り分け処理のための <code>SELECT</code> 文は 1つでしたが、今回これを 3つに増やしており、それぞれコンテナー0,1,2 と対応しています。</p>
<p>振り分けの出力はそれぞれ異なる Azure Event Hubs 名前空間で、その先で Azure Stream Analytics ジョブが単純な <code>SELECT</code> 文でログを全件取得しています。</p>
<p>例えば、コンテナー0 に関する <code>StorageRead</code> ログは、後続の Azure Stream Analytics ジョブでは以下のクエリで処理をしています。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    <span class="operator">*</span></span><br><span class="line"><span class="keyword">INTO</span></span><br><span class="line">    [cosmos<span class="operator">-</span>container0<span class="operator">-</span>stloganalytics20230208a0<span class="operator">-</span><span class="type">blob</span><span class="operator">-</span>StorageRead]</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">    [evh<span class="operator">-</span>stloganalytics20230208a0<span class="operator">-</span>container0<span class="operator">-</span><span class="type">blob</span><span class="operator">-</span>storageread]</span><br></pre></td></tr></table></figure>

<p>コンテナー1,2 についても、やり方は同様です。</p>
<p>それぞれの後続の Azure Stream Analytics ジョブは、今回それぞれ <a target="_blank" rel="noopener" href="https://learn.microsoft.com/azure/cosmos-db/introduction">Azure Cosmos DB</a> <a target="_blank" rel="noopener" href="https://learn.microsoft.com/azure/cosmos-db/nosql/">for NoSQL</a> にログを格納することとしています。</p>
<p>クエリを</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    <span class="keyword">LEFT</span>(record.arrayvalue.time, <span class="number">10</span>) <span class="keyword">AS</span> <span class="type">date</span>,</span><br><span class="line">    record.arrayvalue.<span class="operator">*</span></span><br><span class="line"><span class="keyword">INTO</span></span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>

<p>としたのはそのためです。パーティション キーとして年月日を使用することを想定し、 <code>time</code> フィールドから <code>date</code> フィールドを生成しています。</p>
<p><code>StorageRead</code> のプラットフォーム ログを振り分けるしくみの、最終的な構成図は以下の通りです。</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-diagram-00001.png" class="slug">

<p>実際に各 Azure Cosmos DB for NoSQL のコレクションにログが振り分けられていることも確認できます。</p>
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00078.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00079.png" class="slug">
<img src="/2023/02/07/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query/Filter-ADLSGen2-logs-separated-by-container-name-in-Azure-Stream-Analytics-query-00080.png" class="slug">

<p>将来的に <code>StorageWrite</code> および <code>StorageDelete</code> のプラットフォーム ログも同様に処理したい場合は、一連の Azure Event Hubs インスタンス (名前空間ではなく) と Azure Stream Analytics ジョブのセットを増やしていく形になります。</p>
<h2 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h2><p>Azure Stream Analytics のクエリ内で ADLS Gen2 のログをコンテナー名ごとにフィルタリングする方法について解説しました。<br>特に出力先の構成については、企業や組織のポリシー等に依存するところですので、それに合わせてカスタマイズしていただければと思います。<br>また、今回は ADLS Gen2 のプラットフォーム ログのうち <code>StorageRead</code> のみを扱いましたが、同じ要領で他のログを振り分けることができます。 (メトリックにはコンテナー名が含まれていないので、今回の課題に則した振り分けはできません。)<br>ぜひこれらのログを活用し、セキュリティ監査に役立ててください。</p>
<h2 id="See-also"><a href="#See-also" class="headerlink" title="See also"></a>See also</h2><ul>
<li><a target="_blank" rel="noopener" href="https://learn.microsoft.com/azure/architecture/framework/security/monitor-logs-alerts">Azure でのセキュリティ アラート - Microsoft Azure Well-Architected Framework | Microsoft Learn</a></li>
<li><a target="_blank" rel="noopener" href="https://learn.microsoft.com/azure/storage/blobs/monitor-blob-storage?tabs=azure-portal">Azure Blob Storage の監視 | Microsoft Learn</a></li>
<li><a target="_blank" rel="noopener" href="https://learn.microsoft.com/azure/storage/blobs/blob-storage-monitoring-scenarios">Azure Blob Storage の監視に関するベスト プラクティス | Microsoft Learn</a></li>
<li><a target="_blank" rel="noopener" href="https://learn.microsoft.com/azure/event-hubs/">Azure Event Hubs のドキュメント | Microsoft Learn</a></li>
<li><a target="_blank" rel="noopener" href="https://learn.microsoft.com/azure/stream-analytics/">Azure Stream Analytics のドキュメント | Microsoft Learn</a></li>
<li><a target="_blank" rel="noopener" href="https://learn.microsoft.com/stream-analytics-query/stream-analytics-query-language-reference">Stream Analytics クエリ言語リファレンス - Stream Analytics Query | Microsoft Learn</a></li>
<li><a target="_blank" rel="noopener" href="https://learn.microsoft.com/azure/cloud-adoption-framework/ready/azure-best-practices/resource-abbreviations">Azure リソースの省略形の例 - Cloud Adoption Framework | Microsoft Learn</a></li>
</ul>
</div></header><footer class="post__foot u-cf"><ul class="post__tag u-fl"><li class="post__tag__item"><a class="post__tag__link" href="/tags/Azure/">Azure</a></li><li class="post__tag__item"><a class="post__tag__link" href="/tags/Azure-Data-Lake-Storage-Gen2/">Azure Data Lake Storage Gen2</a></li><li class="post__tag__item"><a class="post__tag__link" href="/tags/Azure-Stream-Analytics/">Azure Stream Analytics</a></li><li class="post__tag__item"><a class="post__tag__link" href="/tags/Azure-Event-Hubs/">Azure Event Hubs</a></li></ul></footer></article></main><footer class="foot"><div class="foot-copy">&copy; 2021 - 2023 kt.log<a class="icp-a" href="https://github.com/k14i" target="view_window">by kt (Keisuke Takahashi)</a></div></footer><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));
ga('create','G-9XBBR7M7V2');
ga('send','pageview');</script>
<script src="/js/scroller.js"></script>

<script src="/js/main.js"></script>
</body></html>